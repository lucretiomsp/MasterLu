"
I am a **MicroDown Text Presenter** (`MicTextPresenter`) that displays useful lessons about **Sound Synthesis**.
These lessons serve as a compendium for `MasterLu` and to learn using **Phausto**, while also offering insights into sound synthesis in general.

The main inspiration for these leasons is the super cool [YouTube channel](https://www.youtube.com/playlist?list=PL7w4cOVVxL6HWGokiABmiZnssYQjo_UFd) by Professor [Simon Hutchinson](https://simonhutchinson.com/) 

To explore the lessons, just open a Playground and evaluate
```language=Pharo
SynthesisFundamentals new open.
```

Alternatiely, you can click on one of the executable examples available on the class side.
"
Class {
	#name : 'SynthesisFundamentals',
	#superclass : 'MicTextPresenter',
	#instVars : [
		'content'
	],
	#classVars : [
		'MLuInstance'
	],
	#category : 'MasterLu',
	#package : 'MasterLu'
}

{ #category : 'accessing - text' }
SynthesisFundamentals class >> fiveTypeOfSynthesis [

	| lessonText |
	lessonText := '
# Five Types of Synthesis

We can list a huge number of synthesis techniques, but we can break them into 5 macro-categories:

- **Subtractive Synthesis**
- **Additive Synthesis**
- **Modulation Synthesis / Distortion Synthesis**
- **Physical-Modeling Synthesis**
- **Sample-Based Synthesis / WaveTable synthesis**

## Subtractive Synthesis
A synthesis technique that involves the manipulation of specific frequencies through the use of filters (such as `ButterworthLPHP` , `MKOFilter` or `ResonatorFilter` subclasses), shaping the timbre of the sound by altering its harmonic content.

## Additive Synthesis
A synthesis technique that combines simple waveforms at varying frequencies, amplitudes, and phases to generate complex waveforms. [Hammond organs](https://en.wikipedia.org/wiki/Hammond_organ) or [Thelharmoniums](https://en.wikipedia.org/wiki/Telharmonium) are simple examples of _Additive Synthesis_.

## Modulation Synthesis / Distortion Synthesis
A synthesis technique that alters the frequency or amplitude of a waveform using another waveform, creating complex timbres through techniques like FM ([Frequency Modulation](https://en.wikipedia.org/wiki/Frequency_modulation_synthesis)) or AM ([Amplitude Modulation](https://en.wikipedia.org/wiki/Amplitude_modulation)) synthesis.
In contrast, distortion synthesis shapes sound by intentionally clipping or transforming the waveform, adding harmonics and a harsher character, often used to produce rich, gritty tones.

## Physical-Modeling Synthesis
A synthesis technique n which the waveform is generated by computing a mathematical model that simulates the physical properties of a sound source, usually a musical instrument. By accurately modeling factors like resonance, material characteristics, and excitation methods, it can produce highly realistic and expressive sounds.  `ModalPercussion` , `StringInstruments` and `WindInstruments` subclasses are examples of _Physical-Modeling Synthesis_.

## Sample-Based Synthesis / WaveTable synthesis
A synthesis technique that generates sound by playing back pre-recorded audio samples, allowing for realistic reproduction of acoustic instruments and complex textures. In contrast, wavetable synthesis relies on cycling through pre-defined waveforms stored in tables, enabling efficient and versatile sound design by smoothly morphing between different waves. `TpSampler` is an example of _Sample-Based Synthesis_.

### Granular Synthesis
### Linear Arithmetic Synthesis
A synthesis technique invented by [Roland Corporation](https://en.wikipedia.org/wiki/Roland_Corporation) that combines sample-based and subtractive synthesis with the sample sound providing the initial [transient](https://en.wikipedia.org/wiki/Transient_(acoustics)) of the sound. `ModalPercussion` , `StringInstruments` and `WindInstruments` subclasses are examples of _Physical-Modeling Synthesis_.

'.
	^ lessonText
]

{ #category : 'accessing - text' }
SynthesisFundamentals class >> fiveTypeOfSynthesisModules [

	| lessonText |
	lessonText := '
# Five Types of Synthesis Modules

There are tons of synthesizers and software out there, but a really helpful way to approach them is by thinking about categories of modules.
We can break down any synthesizer into these 5 Synthesis Modules:
- **Generators**
- **Combiners**
- **Modifiers**
- **Time-Variant Controllers (TVCs)**
- **Storers (Storage)**

## Generators
**Generators** are sources of sound. They include `Oscillators`, `PhysicalModels` , `Noise` generators, and Samplers (such as `TpSampler`). In essence, they are components that produce audio signals.

## Combiners
**Combiners** are synthesis modules that combine audio from two ore more sources. _Mixers_ and _Crossfaders_ are example of **Combiners**. Most synthesizers use multiple *Generators** which  are then combined together to form the output.

## Modifiers
`Saturators` , _Filters_ (all the subclasses of `PhFilter`) , _Effects_ (such as `FlangerMono`, `CryBaby` or `AutoWah`) are all  **Modifiers**. These synthesis modules change the sound material sent into them.

## Time-Variant Controllers (TVCs)
These are synthesis s that generates a **control signal**. These are modules such as _Envelope Generators_(like `ADSREnv` or `AREnv`) _Low Frequency Oscillators_(`LFOForModulation`). They generate control signals that vary over time that can modulate parameters and reproduce _vibrato_ (a modulation of the pitch), _tremolo_(a modulation of the amplitude) or _timbre modulation_(which alter harmonic or spectral content).

## Storers (Storage)
A synthesis module that holds data (such as _wavetables_ , _soundfiles_ and so on)

	'.
	^ lessonText
]

{ #category : 'example' }
SynthesisFundamentals class >> lesson1 [

<script>
self new open.
]

{ #category : 'example' }
SynthesisFundamentals class >> lesson2 [

	<script>
	self new
		content: self fiveTypeOfSynthesis;
	
		open
]

{ #category : 'example' }
SynthesisFundamentals class >> lesson3 [

	<script>
	self new
		content: self timeVariantControllers;
		open
]

{ #category : 'accessing - text' }
SynthesisFundamentals class >> timeVariantControllers [

	| lessonText |
	lessonText := '
## Time-Variant Controllers
Musical expression requires change over time. When we think about music we think about notes that change over time. Even in [Drone music](https://en.wikipedia.org/wiki/Drone_music) the _timbre_ changes over time.
**Modulation** is a another word for a variation over time induced by a control signal.
This change over time can be obtained by turning a knob on a synthesiser or on a GUI or can be automated in synthesis through _Time-Variant Controllers_ such as **Envelope Generators** and **Low Frequency Oscillators.
**Phausto** , like the **Faust** compiler at its core,  does not distinguish between _audio rate_ and _control rate_ signals, as all _Unit Generators_ (or _Faust Functions_) output signals at [audio rate](https://en.wikipedia.org/wiki/Sampling_(signal_processing). The only exceptions are the signals generated by **UI Elements**, such as `PhHSlider`, that run at a slower rate than audio rate.

## Envelope Generators

**Envelope Generators** produce _non-periodic_ control signals.It means they are shapes triggered by a _gate_ signal (such as a `Phbutton` or a `Pulse`). In keyboard controlled synthesizers, this gate signal is activated when a key is pressed. The envelope generator was developed by [Robert Moog](https://en.wikipedia.org/wiki/Robert_Moog) in the 1960s, with the fundamental contribution of his collaborator, [Herbert Deutsch](https://en.wikipedia.org/wiki/Herbert_Deutsch).
An Envelope is specified by a **time** and a **level** which determine what level is reached after a certain period of time. The different time/level parts of the Envelope are called _stages_; different _Envelopes_ have a different number of stages. The most common `ADSREnv` has 4 stages: _Attack_ , _Decay_ , _Sustain_ , _Release_ . `AREnv` has 2 stages while `AHDSREnvBias` has 5 stages.
For example, in an _ADSR_ Envelope, after the Envelope is **triggered**:
- _Attack_ is the amount of time it takes to the _Envelope_ to reach its maximum level.
- _Decay_ is how quickly the sound drops to the _Sustain_ level after the _Attack_.
- _Sustain_ is the **level** at which the signal stays (after the initial _Attack_ and _Decay_) as long as the _ADSR_ is triggered (i.e., the key is pressed).
- _Release_ is how quickly the signal returns to zero once the _ADSR_ is no longer triggered.
_ADSR_ Envelope is very common because it is especially useful for shaping amplitudes, as most acoustic instruments naturally exhibit its four stages. _ADSR_ and the other **Envelope Generators** do not have to be use solely for controlling amplitudes, they can be used to control many other parameters, such as  a filter frequency or an oscillator pitch.


## Low Frequency Oscillators (LFOs)
LFOs (such as `LFOForModulation` subclasses) are modules that produce _periodic_ controls signal at specified sub-audio — that is, frequencies below 20 Hz, which is the lower threshold of the human [hearing range](https://en.wikipedia.org/wiki/Hearing_range) ). While they don’t produce audible sound, their slow oscillations can modulate various parameters in a synthesizer, such as pitch, amplitude, and filter frequency. This allows LFOs to create dynamic changes in sound over time, adding movement and texture to a sound.


	'.
	^ lessonText
]

{ #category : 'accessing' }
SynthesisFundamentals >> content [ 

^ content
]

{ #category : 'accessing' }
SynthesisFundamentals >> content: aString [

	content := self text: (Microdown asRichText: aString)
]

{ #category : 'initialization' }
SynthesisFundamentals >> initialize [

	super initialize.
	self content: self class  fiveTypeOfSynthesisModules 
]

{ #category : 'initialization' }
SynthesisFundamentals >> initializeWindow: aWindowPresenter [

	aWindowPresenter initialExtent: 900 @ 900.
	aWindowPresenter title: 'Synthesis Fundamentals'
]
